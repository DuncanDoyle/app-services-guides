[id="chap-using-servicediscovery"]
= Service Discovery and Binding in your OpenShift Cluster {product-long}
ifdef::context[:parent-context: {context}]
:context: using-service-discovery

////
START GENERATED ATTRIBUTES
WARNING: This content is generated by running npm --prefix .build run generate:attributes
////


:community:
:imagesdir: ./images
:product-long: bf2fc6cc711aee1a0c2a
:product: bf2
// Placeholder URL, when we get a HOST UI for the service we can put it here properly
:service_url: https://localhost:1234/
:property-file-name: bf2.properties

:signup_link: https://localhost:1234/
// Other upstream project names
:samples-git-repo: https://github.com/bf2fc6cc711aee1a0c2a/guides

////
END GENERATED ATTRIBUTES
////

// Purpose statement for the assembly
[role="_abstract"]
When building applications on top of OpenShift platform we often see need to 

.Prerequisites
* A command-line terminal application
* Kubectl or OpenShift CLI installed https://docs.openshift.com/container-platform/4.7/cli_reference/openshift_cli/getting-started-cli.html
* Access to the OpenShift Cluster
* RHOAS CLI installed - Please follow https://github.com/bf2fc6cc711aee1a0c2a/guides/tree/main/rhoas-cli guide

// Condition out QS-only content so that it doesn't appear in docs.
// All QS anchor IDs must be in this alternate anchor ID format `[#anchor-id]` because the +ascii splitter relies on the other format `[id="anchor-id"]` to generate module files.
ifdef::qs[]
[#description]
Learn how to use RHOAS Service Discovery to automatically connect Application Services to your apps running on OpenShift Kubernetes cluster in {product-long}.

[#introduction]
Welcome to the {product-long} Service Discovery quick start. In this quick start, you'll learn how to use RHOAS CLI to automatically link your Kafka Service (and other services in the future)  {product-long}.
endif::[]

[id="proc-installing-operator_{context}"]
== Installing and verifying RHOAS Operator

RHOAS Operator (Preview) creates instances of Red Hat OpenShift Application Services in your cluster. Operator connects with Application services giving you ability to embed connection details to services like OpenShift Streams for Apache Kafka and more.

Red Hat OpenShift Application Services, when added to Red Hat OpenShift, 
provide a streamlined developer experience for building, deploying, 
and scaling cloud-native applications in open hybrid-cloud environments. 

Operator will enable developers to connect with their Application Services directly in their own cluster by using
link:https://github.com/redhat-developer/app-services-cli[RHOAS cli] and OpenShift Console UI.

Operator currently enables developers to connect with their Red Hat OpenShift Streams for Apache Kafka (RHOSAK) instances.

[.screencapture]
.Relationship between RHOAS Operator OpenShift UI and RHOAS CLI
image::rhoas-operator.png[Operator and CLI relationships]

NOTE: RHOAS Operator is already installed on various environments like OpenShift Developer Sandbox, before installation process 

NOTE: Installation procedure assumes that you have access to install operators in openshift-namespace on your cluster. 

.Procedure
. Please login to your OpenShift UI instance (if you do not have OpenShift instance you can use https://developers.redhat.com/developer-sandbox and skip this procedure entirely)
. Go to "Administrator" > "Operators" > "Operator Hub"
. Type "RHOAS" in search tab 
. Select "RHOAS" tile
. Leave select "All namespaces" option checked and Press install to install your operator
. Please wait for operator to install.

[id="proc-inspecting-operator_{context}"]
== Verifying your connection to RHOAS operator

RHOAS CLI "cluster" command provides the way to expose connection details for application services like Streams for Apache Kafka.
"rhoas cluster status" command can be used to verify RHOAS operator installation.

.Procedure
* On the command line, enter the following commands to connect your Kafka
"rhoas cluster status"
 +
.Verification
ifdef::qs[]
* Please inspect output of the command and check if RHOAS Operator is installed.
* Output from the command contains: "RHOAS Operator: Installed"
endif::[]

[id="proc-connecting-kafka_{context}"]
== Connecting Apache Kafka Service to your cluster

Now we can connect our Kafka instance to our cluster using 
"rhoas cluster connect"

.Procedure
. Execute "rhoas cluster connect"
. Select service instance you want to connect to your OpenShift cluster
. Verify namespace that will be used to create service instances
. Confirm process by typing `y`
 
.Verification
ifdef::qs[]
* Output from the command contains: "KafkaConnection successful installed on your cluster"
endif::[]

[id="proc-provisioning-example-application_{context}"]
== Provision example application

In this step we going to use sample Node.js application that will have our Kafka credentials injected

.Procedure
. Not sure if we do Quarkus guide here and bind guide later

[id="proc-binding-kafka_{context}"]
== Connecting your service with running application

Once Application is running we can now connect our service 

.Procedure
. Execute "rhoas cluster bind"
. Command will automatically detect our application and single Kafka service in our namespace and inject connection details to the running application

ifdef::qs[]
[#conclusion]
Congratulations! You successfully completed the {product} Service Discovery quick start.
endif::[]

ifdef::parent-context[:context: {parent-context}]
ifndef::parent-context[:!context:]
