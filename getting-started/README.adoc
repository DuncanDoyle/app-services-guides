////
START GENERATED ATTRIBUTES
WARNING: This content is generated by running npm --prefix .build run generate:attributes
////

:imagesdir: ./images
:product-long: Streams for Apache Kafka
:product: Streams for Apache Kafka
// Placeholder URL, when we get a HOST UI for the service we can put it here properly
:service_url: https://localhost:1234/

////
END GENERATED ATTRIBUTES
////

[id="chap-getting-started"]
= Getting Started with {product-long}
ifdef::context[:parent-context: {context}]
:context: getting-started

// Purpose statement for the assembly
[role="_abstract"]
As a developer of cloud applications and services, you can use the {product-long} cloud service to create and set up Kafka instances and connect your applications and services to these instances. {product} is a fully managed cloud service that enables you to implement Kafka data-streaming functionality in your applications without having to manually install, set up, and maintain your own Kafka clusters.

*<@SME: I'm trying for a clear value/why statement above. Feel free to tweak or correct.>*

*<@SME: What prereqs do we need below for the entire story?>*

.Prerequisites
* You have a subscription to {product-long}. For more information about signing up, see *<@SME: Wdyt?>*.
* You have access to the {product} web console.
* You have access to the applications or services that you want to connect to a Kafka instance in {product-long}.

// Condition out QS-only content so that it doesn't appear in docs.
// All QS anchor IDs must be in this alternate anchor ID format `[#anchor-id]` because the ascii splitter relies on the other format `[id="anchor-id"]` to generate module files.
ifdef::qs[]
[#description]
Learn how to create and set up your first Apache Kafka instance in {product-long}.

[#introduction]
Welcome to the {product-long} Getting Started quick start. In this quick start, you will learn how to create and inspect a Kafka instance, create a service account so that you can connect to the instance, and create a topic in the instance.
endif::[]

[id="con-product-overview_{context}"]
== {product-long}

{product-long} is a fully managed cloud service running on https://www.openshift.com/products/dedicated/[OpenShift Dedicated]. {product} enables you to implement Kafka data-streaming functionality in your applications without having to manually install, set up, and maintain your own Kafka clusters. With {product}, you can share data between microservices and other applications with high throughput and low latency. {product} includes AMQ Streams functionality that makes Kafka an OpenShift-native offering with operators that simplify the deployment, configuration, management, and use of Kafka on OpenShift.

[id="proc-creating-kafka-instance_{context}"]
== Creating a Kafka instance in {product}

A Kafka instance in {product} includes a Kafka cluster, bootstrap server, and other required configurations for connecting to Kafka producer and consumer services. You can use the {product} web console to create and configure a Kafka instance for your applications or services.

ifdef::docs[]
.Prerequisites
* You are logged in to the {product} web console at {service-url}.
endif::[]

.Procedure
. In the *Streams for Apache Kafka* page of the web console, click *Create Kafka instance* and define the following instance details. Some values currently have only one option.
* *Instance name*: Enter a unique hyphenated name for the instance, such as `my-first-kafka-instance` in this example.
* *Cloud provider*: Select `Amazon Web Services`.
* *Cloud region*: Select `US East, N. Virginia`.
* *Availability zones*: Select `Multi`.
. Click *Create instance* to start the provision and deployment process of your Kafka instance.
+
--
.Kafka instance configuration details
image::sak-configure-kafka-instance.png[Image of instance configuration details in Create Kafka instance window]

The new Kafka instance is listed in the instances table. When the instance *Status* becomes *Ready*, you can start using the Kafka instance.

.New Kafka instance in Ready state
image::sak-kafka-instance-ready.png[Image of new Kafka instance in Ready state]
--
. On the right side of the Kafka instance in table, use the options icon (three vertical dots) to view instance details, connect to the instance, or delete the instance as needed.
+
.Kafka instance options menu
image::sak-kafka-instance-options.png[Image of Kafka instance options menu]

////
// Commenting out the following for now, which belongs in an onboarding tour (Stetson, 4 March 2021)

When you're in the {Product_short} environment, you will see a left menu panel. This panel provides access to all resources related to the service, including the `Quick Starts` and `Documentation`.

In the lower left of the screen you'll see a lightbulb icon. This icon gives access to the `Resource Center`. Here you can find the latest information about the service, like product updates, upcoming events, etc.

image::sak-crc-resource-center.png[Image of Resource Center in web console]

The center of the page shows you the list of Kafka instances that are currently running within your organisation. If this is your, or your organisations, first interaction with {Product_short}, this list will be empty.

image::sak-kafka-overview.png[Image of initial empty instances table]
////

[id="proc-connecting-kafka-instance_{context}"]
== Connecting to a Kafka instance in {product}

To connect your applications or services to a Kafka instance in the {product} web console, you must copy and save the bootstrap server location and the generated credentials for the instance. {product-long} uses the SASL/PLAIN authentication mechanism over TLS to provide secure connections between your applications and Kafka instances. When you generate credentials for a Kafka instance, {product} creates a service account that contains the generated user name and password associated with the instance.

.Prerequisites
* You have created a Kafka instance in the {product} web console.

.Procedure
. In the *Streams for Apache Kafka* page of the web console, on the right side of the relevant Kafka instance, select the options icon (three vertical dots) and click *Connect to instance*.
. In the *Connection* page, copy the *External server* address to a secure location. Your application requires this server address to connect to the Kafka instance.
. Click *Generate credential*, copy the *Client ID* and *Client secret* to a secure location, and select the confirmation check box to close the credentials window. Your application requires these credentials to authenticate the connection to the Kafka instance.
+
IMPORTANT: The generated credentials are displayed only one time, so ensure that you have successfully and securely saved the copied credentials before closing the credentials window.

. Use the server and client information that you copied to configure your application connection details accordingly.

[id="proc-creating-kafka-topic_{context}"]
== Creating a Kafka topic in {product}

After you create a Kafka instance and connect your applications or services to that instance, you can create Kafka topics to start producing and consuming messages in your services.

.Prerequisites
* You have created a Kafka instance in the {product} web console and connected your applications or services to it.

.Procedure
. In the *Streams for Apache Kafka* page of the web console, select the Kafka instance to which you want to add a topic.
. Click *Create topic* and follow the guided steps to define the topic details. Click *Next* to complete each step and click *Finish* to complete the setup.
+
--
.Guided steps to define topic details
image::sak-create-topic.png[Image of wizard to create a topic]

* *Topic name*: Enter a unique hyphenated topic name, such as `my-first-kafka-topic` in this example.
* *Partitions*: Set the number of partitions for this topic. This example sets the partition to `1` for a single partition. Partitions are distinct lists of messages within a topic and enable parts of a topic to be distributed over multiple brokers in the cluster. A topic can contain one or more partitions, enabling producer and consumer loads to be scaled.
+
NOTE: You can increase the number of partitions later, but you cannot decrease them.
+

* *Message retention*: Set the message retention time to the relevant value and increment. This example sets the retention to `7 days`. Message retention time is the amount of time that messages are retained in a topic before they are deleted or compacted, depending on the cleanup policy.
* *Replicas*: Set the number of partition replicas for the topic and the minimum number of follower replicas that must be in sync with a partition leader. This example sets the replica factor and in-sync replicas to `1`. Replicas are copies of partitions in a topic. Partition replicas are distributed over multiple brokers in the cluster to ensure topic availability if a broker fails. When a follower replica is in sync with a partition leader, the follower replica can become the new partition leader if needed.

The new Kafka topic is listed in the topics table. The messages between the Kafka instance and the connected services are now streamed in this configured topic.
--
. On the right side of the Kafka instance in the table, use the options icon (three vertical dots) to edit or delete the topic as needed.

.Edit or delete Kafka topic
image::sak-edit-topic.png[Image of topic options to edit or delete]

[role="_additional-resources"]
== Additional resources
* *<Placeholder for links to other upcoming docs>*

ifdef::parent-context[:context: {parent-context}]
ifndef::parent-context[:!context:]
